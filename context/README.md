# LLM Output Directory

This directory stores all outputs and results generated by Large Language Models (LLMs) such as Claude, Gemini, GPT, and other AI assistants.

## Purpose

The `context/` directory serves as a centralized location to:
- Store LLM-generated content and outputs
- Track AI-generated artifacts for review and reference
- Maintain a history of AI-assisted work
- Enable collaboration by sharing LLM outputs with team members

## Directory Structure

```
context/
├── README.md          # This file - documentation
├── content/           # Raw LLM-generated content
│   ├── claude/       # Outputs from Claude
│   ├── gpt/          # Outputs from GPT models
│   ├── gemini/       # Outputs from Google Gemini
│   └── other/        # Outputs from other LLMs
└── output/           # Processed/finalized LLM results
    ├── code/         # Generated code files
    ├── docs/         # Generated documentation
    ├── plans/        # Generated planning documents
    └── analysis/     # Generated analysis and reports
```

## Usage Guidelines

### When to Use `content/`

Store raw, unprocessed LLM outputs in `content/`:
- Direct copy-paste from LLM conversations
- Initial drafts and rough outputs
- Multiple versions or iterations
- Experimental or exploratory outputs

**Example use cases:**
- Copying code suggestions from Claude
- Saving GPT-generated documentation drafts
- Storing Gemini analysis results
- Keeping conversation transcripts

### When to Use `output/`

Store finalized, processed results in `output/`:
- Reviewed and approved LLM outputs
- Code that has been integrated into the project
- Documentation that's been edited and finalized
- Analysis that's been validated

**Example use cases:**
- Code files ready to be integrated
- Finalized documentation from LLM assistance
- Approved planning documents
- Validated analysis reports

## Organization by LLM

### Claude Outputs
Store Claude-generated content in `content/claude/`:
```
content/claude/
├── code-generation/
├── documentation/
├── planning/
└── analysis/
```

### GPT Outputs
Store GPT-generated content in `content/gpt/`:
```
content/gpt/
├── code-generation/
├── documentation/
├── planning/
└── analysis/
```

### Gemini Outputs
Store Gemini-generated content in `content/gemini/`:
```
content/gemini/
├── code-generation/
├── documentation/
├── planning/
└── analysis/
```

## File Naming Conventions

Use descriptive, timestamped filenames:

**Format:** `[date]-[llm]-[type]-[description].[ext]`

**Examples:**
- `2026-01-20-claude-code-api-routes.ts`
- `2026-01-20-gpt-docs-user-guide.md`
- `2026-01-20-gemini-analysis-performance.md`
- `2026-01-20-claude-planning-architecture.md`

## Best Practices

### 1. Always Review Before Moving to Output
- Review all LLM-generated content before moving to `output/`
- Validate code for correctness and security
- Check documentation for accuracy
- Verify analysis for completeness

### 2. Keep Original Context
- Include the prompt or question that generated the output
- Note which LLM model was used
- Record the date and version
- Add any relevant context or constraints

### 3. Version Control
- Commit LLM outputs to git for tracking
- Use meaningful commit messages
- Tag significant outputs
- Maintain a changelog for important outputs

### 4. Documentation
- Add comments explaining what the LLM generated
- Note any manual edits or modifications
- Document why the output was generated
- Include links to related issues or tasks

## Example Workflow

### Step 1: Generate Content
Ask an LLM (e.g., Claude) to generate code or documentation.

### Step 2: Save to Content
Save the raw output to `content/claude/[category]/[filename]`

### Step 3: Review and Edit
Review the output, make necessary edits, and validate.

### Step 4: Move to Output
Once finalized, move or copy to `output/[category]/[filename]`

### Step 5: Integrate
Use the output in your project (e.g., copy code to `src/`, docs to `docs/`)

## Integration with Project

LLM outputs in this directory are:
- **Not automatically integrated** - Manual review required
- **Version controlled** - Tracked in git
- **Documented** - Each output should have context
- **Reviewed** - Team members can review and provide feedback

## Security Considerations

- **Never commit sensitive data** - API keys, passwords, tokens
- **Review code for vulnerabilities** - LLMs may generate insecure code
- **Validate all outputs** - Don't blindly trust LLM suggestions
- **Check licenses** - Ensure generated code respects licenses

## Related Directories

- `.claude/skills/` - Claude Skills definitions (not outputs)
- `docs/` - Final documentation (may include LLM-generated content)
- `src/` - Application code (may include LLM-generated code)
- `planning/` - Planning documents (may include LLM-generated plans)

## Quick Reference

**Save raw LLM output:**
```bash
# Save to content directory
echo "[LLM output]" > context/content/claude/code-generation/2026-01-20-api-routes.ts
```

**Move to output after review:**
```bash
# Move reviewed content to output
mv context/content/claude/code-generation/2026-01-20-api-routes.ts \
   context/output/code/2026-01-20-api-routes.ts
```

**View all LLM outputs:**
```bash
# List all content
find context/content -type f

# List all outputs
find context/output -type f
```

## Notes

- This directory is included in version control
- Large files may need to be added to `.gitignore`
- Consider using Git LFS for very large outputs
- Regular cleanup of old/unused outputs is recommended

